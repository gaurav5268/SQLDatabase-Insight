# Natural Language Database Insights Project (SQLite + CSV Dataset)

A database-driven project that creates a fully structured SQLite database from CSV files
and allows users to explore and analyze the database using natural-language queries.

This database is later integrated with a Streamlit + LLM based application
to generate SQL queries, insights, tables, and visual charts automatically.

The project includes:

âœ” Automatic SQLite Database Creation  
âœ” Schema-Based Table Generation  
âœ” Foreign-Key Enforced Relationships  
âœ” Clean CSV Import Pipeline  
âœ” Transaction-Safe Data Loading  
âœ” Automatic Database Overwrite & Rebuild  
âœ” Backend Dataset for Natural Language SQL Insights  

---

## Problem Statement

Database analysis often requires:

- Writing SQL queries manually  
- Understanding relational schema  
- Debugging foreign-key relationships  
- Handling data imports safely  

For beginners, analysts, and students â€” this becomes time-consuming and difficult.

This project solves that problem by:

- Automatically creating database from schema  
- Loading CSV data in dependency-safe order  
- Enforcing referential integrity  
- Providing a clean & reproducible dataset  
- Enabling natural-language query insights  

The database is further used for:

ðŸŸ¢ SQL Learning & Practice  
ðŸŸ¢ Data Analytics & Exploration  
ðŸŸ¢ Natural Language Query â†’ SQL Conversion  

---

## Dataset

The database is created from structured CSV files inside the `data/` folder.

Tables included:

| Table Name | Description |
|----------|-----------|
| employee | Employee personal & demographic details |
| department | Department master data |
| dept_emp | Employeeâ€“Department mapping |
| title | Employee role & designation |
| salary | Salary records |

Data is imported in correct dependency order to maintain constraints.

---

## Database Pipeline & Processing

Step 1 â€” Enable Foreign Key Enforcement  
Step 2 â€” Execute Schema from `schema.sql`  
Step 3 â€” Load CSV files in referential order  
Step 4 â€” Clean and normalize column headers  
Step 5 â€” Insert records into tables  
Step 6 â€” Commit and finalize SQLite database  

The script ensures:

âœ” No partial imports  
âœ” No broken relationships  
âœ” No duplicate database state  

---

## Business / Learning Objective

This project is designed for:

âœ” SQL & Database Concepts Learning  
âœ” Data Engineering Practice  
âœ” ETL & Dataset Structuring  
âœ” Analytics Project Backend  
âœ” Natural Language Insight Systems  

It supports natural-language interactions such as:

- "Show employees working in Finance department"
- "List salaries of Senior Engineers"
- "Department wise employee count"
- "Generate chart of employee distribution"

The system converts queries to SQL and fetches results automatically.

---

## Tech Stack

**Languages**
- Python

**Database**
- SQLite

**Libraries**
- Pandas

**Data Source**
- CSV Files + Schema SQL

**Usage**
- Backend for Text-to-SQL Insights System

---

## Project Architecture

data/      
â”œâ”€â”€ schema.sql
â”œâ”€â”€ employee.csv
â”œâ”€â”€ department.csv
â”œâ”€â”€ dept_emp.csv
â”œâ”€â”€ title.csv
â””â”€â”€ salary.csv

.env   
app.py
main.py
prompts.py

build_database.py
database.db

requirements.txt
README.md

## Installation & Setup

### 1) Install Dependencies

pip install pandas


---

### 2) Run Database Builder Script

python build_database.py


A fresh SQLite database is generated:

database.db

Existing database is:

âœ” deleted  
âœ” rebuilt  
âœ” reloaded with fresh data  

to maintain clean and reproducible state.

---

## Key Highlights

âœ” Structured relational dataset  
âœ” Completely automated DB creation  
âœ” Overwrite-safe rebuild mechanism  
âœ” Suitable for projects & portfolios  
âœ” Supports LLM + Streamlit insights app  

---

**Gaurav Chauhan**